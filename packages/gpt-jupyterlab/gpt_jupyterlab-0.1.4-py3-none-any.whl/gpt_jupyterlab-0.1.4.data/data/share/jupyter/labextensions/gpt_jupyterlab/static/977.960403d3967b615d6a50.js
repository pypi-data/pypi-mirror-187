"use strict";(self.webpackChunkgpt_jupyterlab=self.webpackChunkgpt_jupyterlab||[]).push([[977],{977:(e,t,o)=>{o.r(t),o.d(t,{GPTButtonExtension:()=>u,continueIcon:()=>s.runIcon,default:()=>g,gptIcon:()=>i,terminateIcon:()=>s.stopIcon});var n=o(923),a=o(667),r=o(172),c=o(859),p=o(671),l=o(878),s=o(152);const i=new s.LabIcon({name:"gpt_jupyterlab:run_gpt",svgstr:'<svg id="openai-symbol" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M29.71,13.09A8.09,8.09,0,0,0,20.34,2.68a8.08,8.08,0,0,0-13.7,2.9A8.08,8.08,0,0,0,2.3,18.9,8,8,0,0,0,3,25.45a8.08,8.08,0,0,0,8.69,3.87,8,8,0,0,0,6,2.68,8.09,8.09,0,0,0,7.7-5.61,8,8,0,0,0,5.33-3.86A8.09,8.09,0,0,0,29.71,13.09Zm-12,16.82a6,6,0,0,1-3.84-1.39l.19-.11,6.37-3.68a1,1,0,0,0,.53-.91v-9l2.69,1.56a.08.08,0,0,1,.05.07v7.44A6,6,0,0,1,17.68,29.91ZM4.8,24.41a6,6,0,0,1-.71-4l.19.11,6.37,3.68a1,1,0,0,0,1,0l7.79-4.49V22.8a.09.09,0,0,1,0,.08L13,26.6A6,6,0,0,1,4.8,24.41ZM3.12,10.53A6,6,0,0,1,6.28,7.9v7.57a1,1,0,0,0,.51.9l7.75,4.47L11.85,22.4a.14.14,0,0,1-.09,0L5.32,18.68a6,6,0,0,1-2.2-8.18Zm22.13,5.14-7.78-4.52L20.16,9.6a.08.08,0,0,1,.09,0l6.44,3.72a6,6,0,0,1-.9,10.81V16.56A1.06,1.06,0,0,0,25.25,15.67Zm2.68-4-.19-.12-6.36-3.7a1,1,0,0,0-1.05,0l-7.78,4.49V9.2a.09.09,0,0,1,0-.09L19,5.4a6,6,0,0,1,8.91,6.21ZM11.08,17.15,8.38,15.6a.14.14,0,0,1-.05-.08V8.1a6,6,0,0,1,9.84-4.61L18,3.6,11.61,7.28a1,1,0,0,0-.53.91ZM12.54,14,16,12l3.47,2v4L16,20l-3.47-2Z"/></svg>'});async function m(e){let t=e.get("openai_key").composite;const o=e.get("code_model").composite,n=e.get("text_model").composite,a=e.get("max_tokens").composite,r=e.get("temperature").composite,p=e.get("presence_penalty").composite,l=e.get("frequency_penalty").composite;if(!t){const o=await c.InputDialog.getText({title:"Provide your OpenAI API Key"});o.value&&(await e.set("openai_key",o.value),t=o.value)}return{openai_key:t,code_model:o,text_model:n,max_tokens:a,temperature:r,presence_penalty:p,frequency_penalty:l}}class u{constructor(e){this.app=e}createNew(e,t){const o=new c.ToolbarButton({className:"gpt-button",label:"GPT",onClick:()=>{this.app.commands.execute("@gpt_jupyterlab/plugin:run_gpt").catch((e=>{console.error(`An error occurred during the execution of jlab-examples:command.\n${e}`)}))},tooltip:"GPT Completion",icon:i});return e.toolbar.insertItem(10,"gpt",o),new n.DisposableDelegate((()=>{o.dispose()}))}}const g={id:"gpt_jupyterlab:plugin",autoStart:!0,optional:[a.ISettingRegistry,r.INotebookTracker,c.ICommandPalette],activate:async(e,t,o,n)=>{console.log("JupyterLab extension gpt_jupyterlab is activated!");const{commands:a}=e;e.docRegistry.addWidgetExtension("Notebook",new u(e)),t&&Promise.all([e.restored,t.load("gpt_jupyterlab:plugin")]).then((([,e])=>{e.changed.connect(m),a.addCommand("@gpt_jupyterlab/plugin:run_gpt",{label:"GPT Completion",execute:async()=>{if(o){const{openai_key:t,code_model:n,text_model:a,max_tokens:r,temperature:c,presence_penalty:s,frequency_penalty:i}=await m(e),u=o.activeCell;if(u){u.setPrompt("â€¦");const e={params:{model:"code"===u.model.type?n:a,prompt:u.editor.model.value.text,temperature:c,max_tokens:r,presence_penalty:s,frequency_penalty:i},openai_key:t};try{const t=await async function(e="",t={}){const o=l.ServerConnection.makeSettings(),n=p.URLExt.join(o.baseUrl,"gpt-jupyterlab",e);let a;try{a=await l.ServerConnection.makeRequest(n,t,o)}catch(e){throw new l.ServerConnection.NetworkError(e)}let r=await a.text();if(r.length>0)try{r=JSON.parse(r)}catch(e){console.log("Not a JSON response body.",a)}if(!a.ok)throw new l.ServerConnection.ResponseError(a,r.message||r);return r}("complete",{body:JSON.stringify(e),method:"POST"});u.editor.model.value.text+=t.choices[0].text}catch(t){console.error(`Error on POST ${e}.\n${t}`)}u.setPrompt("")}}}}),n.addItem({command:"@gpt_jupyterlab/plugin:run_gpt",category:"GPT"})})).catch((e=>{console.error(`Something went wrong when reading the settings.\n${e}`)}))}}}}]);
# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['esdbclient', 'esdbclient.protos.Grpc']

package_data = \
{'': ['*']}

install_requires = \
['grpcio>=1.51.0,<2.0.0', 'protobuf>=4.21.0,<5.0.0', 'typing_extensions']

setup_kwargs = {
    'name': 'esdbclient',
    'version': '0.6',
    'description': 'Python gRPC Client for EventStoreDB',
    'long_description': '# Python gRPC Client for EventStoreDB\n\nThis package provides a Python gRPC client for\n[EventStoreDB](https://www.eventstore.com/). It has been\ndeveloped and tested to work with EventStoreDB LTS version 21.10,\nand with Python versions 3.7, 3.8, 3.9, 3.10, and 3.11.\n\nMethods have typing annotations, the static typing is checked\nwith mypy, and the test coverage is 100%.\n\nNot all the features of the EventStoreDB API are presented\nby this client in its current form, however many of the most\nuseful aspects are presented in an easy-to-use interface (see below).\nFor an example of usage, see the [eventsourcing-eventstoredb](\nhttps://github.com/pyeventsourcing/eventsourcing-eventstoredb) package.\n\n<!-- TOC -->\n* [Installation](#installation)\n* [Getting started](#getting-started)\n  * [Start EventStoreDB](#start-eventstoredb)\n  * [Construct client](#construct-client)\n  * [Append events](#append-events)\n  * [Get current stream position](#get-current-stream-position)\n  * [Read stream events](#read-stream-events)\n  * [Read all recorded events](#read-all-recorded-events)\n  * [Get current commit position](#get-current-commit-position)\n  * [Catch-up subscriptions](#catch-up-subscriptions)\n  * [Persistent subscriptions](#persistent-subscriptions)\n  * [The NewEvent class](#the-newevent-class)\n  * [The RecordedEvent class](#the-recordedevent-class)\n  * [Filter regular expressions](#filter-regular-expressions)\n  * [Stop EventStoreDB](#stop-eventstoredb)\n* [Contributors](#contributors)\n  * [Install Poetry](#install-poetry)\n  * [Setup for PyCharm users](#setup-for-pycharm-users)\n  * [Setup from command line](#setup-from-command-line)\n  * [Project Makefile commands](#project-makefile-commands)\n<!-- TOC -->\n\n## Installation\n\nUse pip to install this package from\n[the Python Package Index](https://pypi.org/project/esdbclient/).\n\n    $ pip install esdbclient\n\nIt is recommended to install Python packages into a Python virtual environment.\n\n\n## Getting started\n\n### Start EventStoreDB\n\nUse Docker to run EventStoreDB from the official container image on DockerHub.\n\n    $ docker run -d --name my-eventstoredb -it -p 2113:2113 -p 1113:1113 eventstore/eventstore:21.10.2-buster-slim --insecure\n\nPlease note, this will start the server without SSL/TLS enabled, allowing\nonly "insecure" connections. This version of this Python client does not\nsupport SSL/TLS connections. A future version of this library will support\n"secure" connections.\n\n\n### Construct client\n\nThe class `EsdbClient` can be constructed with a `uri` that indicates the\nhostname and port number of the EventStoreDB server.\n\n```python\nfrom esdbclient import EsdbClient\n\nclient = EsdbClient(uri=\'localhost:2113\')\n```\n\n### Append events\n\nThe method `append_events()` can be used to append events to\na stream.\n\nThree arguments are required, `stream_name`, `expected_position`\nand `events`.\n\nThe `stream_name` argument is a string that uniquely identifies\nthe stream in the database.\n\nThe `expected_position` argument is an optional integer that specifies\nthe expected position of the end of the stream in the database. That is,\neither a positive integer representing the expected current position of\nthe stream, or `None` if the stream is expected not to exist. If there\nis a mismatch with the actual position of the end of the stream, an exception\n`ExpectedPositionError` will be raised by the client. This accomplishes\noptimistic concurrency control when appending new events. If you need to\nget the current position of the end of a steam, use the `get_stream_position()`\nmethod (see below). If you wish to disable optimistic concurrency, set the\n`expected_position` to a negative integer.\n\nThe `events` argument is a sequence of new event objects to be appended to the\nnamed stream. The class `NewEvent` can be used to construct new event objects.\n\nIn the example below, a stream is created by appending a new event with\n`expected_position=None`.\n\n```python\nfrom uuid import uuid4\n\nfrom esdbclient import NewEvent\n\n# Construct new event object.\nevent1 = NewEvent(\n    type=\'OrderCreated\',\n    data=b\'{}\',\n    metadata=b\'{}\'\n)\n\n# Define stream name.\nstream_name1 = str(uuid4())\n\n# Append list of events to new stream.\ncommit_position1 = client.append_events(\n    stream_name=stream_name1,\n    expected_position=None,\n    events=[event1],\n)\n```\n\nIf the append operation is successful, this method\nwill return the database "commit position" as it was when the\noperation was completed. Otherwise, an exception will be raised.\n\nThe commit position value can be used to wait for downstream\nprocessing to have processed the appended events. For example,\nafter making a command, a user interface can wait before\nmaking a query for an eventually consistent materialised\nview that would be stale if those events have not yet been\nprocessed.\n\nA "commit position" is a monotonically increasing integer representing\nthe position of the recorded event in a "total order" of all recorded\nevents in the database. The sequence of commit positions is not gapless.\nIt represents the position of the event record on disk, and there are\nusually large differences between successive commits.\n\nIn the example below, two subsequent events are appended to an existing\nstream. The sequences of stream positions are zero-based, and so when a\nstream only has one recorded event, the expected position of the end of\nthe stream is `0`.\n\n```python\nevent2 = NewEvent(\n    type=\'OrderUpdated\',\n    data=b\'{}\',\n    metadata=b\'{}\',\n)\nevent3 = NewEvent(\n    type=\'OrderDeleted\',\n    data=b\'{}\',\n    metadata=b\'{}\',\n)\n\ncommit_position2 = client.append_events(\n    stream_name=stream_name1,\n    expected_position=0,\n    events=[event2, event3],\n)\n```\n\nPlease note, the append operation is atomic, so that either all\nor none of a given list of events will be recorded. By design it is only\npossible with EventStoreDB to atomically record events in one stream,\nwhich means each operation must only include events of one stream.\n\nThis method takes an optional argument `timeout` which is a float that sets\na deadline for the completion of the gRPC operation.\n\n\n### Get current stream position\n\nThe method `get_stream_position()` can be used to get the\nposition of the end of a stream (the position of the last\nrecorded event in the stream).\n\n```python\nstream_position = client.get_stream_position(\n    stream_name=stream_name1\n)\n\nassert stream_position == 2\n```\n\nThe sequence of stream positions is gapless. It is zero-based, so that\nthe position of the end of the stream is `0` after one event has been\nappended. The position is `1` after two events have been appended, and\n`2` after three events have been appended, and so on.\n\nIf a stream does not exist, the returned stream position is `None`,\nwhich corresponds to the required expected position when appending\nevents to a stream that does not exist (see above).\n\n```python\nstream_position = client.get_stream_position(\n    stream_name=\'stream-unknown\'\n)\n\nassert stream_position == None\n```\n\nThis method takes an optional argument `timeout` which is a float that sets\na deadline for the completion of the gRPC operation.\n\n\n### Read stream events\n\nThe method `read_stream_events()` can be used to read the recorded\nevents in a stream. An iterable object of recorded events is returned.\n\nOne argument is required, `stream_name`, which is the name of the\nstream to be read. By default, the recorded events in the stream\nare returned in the order they were recorded.\n\nThe example below shows how to read the recorded events of a stream\nforwards from the start of the stream to the end of the stream.\n\n```python\nresponse = client.read_stream_events(\n    stream_name=stream_name1\n)\n```\n\nThe iterable object is actually a Python generator, and we need to\niterate over it to get the recorded events from gRPC.\n\nLet\'s construct a list from the generator, so that we can\ncheck we have the events that were recorded above.\n\n```python\nevents = list(response)\n```\n\nNow that we have a list of events, we can check we got the\nthree events that were appended to the stream.\n\n```python\nassert len(events) == 3\n\nassert events[0].stream_name == stream_name1\nassert events[0].stream_position == 0\nassert events[0].type == event1.type\nassert events[0].data == event1.data\n\nassert events[1].stream_name == stream_name1\nassert events[1].stream_position == 1\nassert events[1].type == event2.type\nassert events[1].data == event2.data\n\nassert events[2].stream_name == stream_name1\nassert events[2].stream_position == 2\nassert events[2].type == event3.type\nassert events[2].data == event3.data\n```\n\nThe method `read_stream_events()` also supports four optional arguments,\n`position`, `backwards`, `limit`, and `timeout`.\n\nThe optional argument `position` is an optional integer that can be used to indicate\nthe position in the stream from which to start reading. This argument is `None`\nby default, which means the stream will be read either from the start of the\nstream (the default behaviour), or from the end of the stream if `backwards` is\n`True` (see below). When reading a stream from a specific position in the stream, the\nrecorded event at that position WILL be included, both when reading forwards\nfrom that position, and when reading backwards from that position.\n\nThe optional argument `backwards` is a boolean, by default `False`, which means the\nstream will be read forwards by default, so that events are returned in the\norder they were appended, If `backwards` is `True`, the stream will be read\nbackwards, so that events are returned in reverse order.\n\nThe optional argument `limit` is an integer which limits the number of events that will\nbe returned. The default value is `sys.maxint`.\n\nThe optional argument `timeout` is a float which sets a deadline for the completion of\nthe gRPC operation.\n\nThe example below shows how to read recorded events in a stream forwards from\na specific stream position to the end of the stream.\n\n```python\nevents = list(\n    client.read_stream_events(\n        stream_name=stream_name1,\n        position=1,\n    )\n)\n\nassert len(events) == 2\n\nassert events[0].stream_name == stream_name1\nassert events[0].stream_position == 1\nassert events[0].type == event2.type\nassert events[0].data == event2.data\n\nassert events[1].stream_name == stream_name1\nassert events[1].stream_position == 2\nassert events[1].type == event3.type\nassert events[1].data == event3.data\n```\n\nThe example below shows how to read the recorded events in a stream backwards from\nthe end of the stream to the start of the stream.\n\n```python\nevents = list(\n    client.read_stream_events(\n        stream_name=stream_name1,\n        backwards=True,\n    )\n)\n\nassert len(events) == 3\n\nassert events[0].stream_name == stream_name1\nassert events[0].stream_position == 2\nassert events[0].type == event3.type\nassert events[0].data == event3.data\n\nassert events[1].stream_name == stream_name1\nassert events[1].stream_position == 1\nassert events[1].type == event2.type\nassert events[1].data == event2.data\n```\n\nThe example below shows how to read a limited number (two) of the recorded events\nin stream forwards from the start of the stream.\n\n```python\nevents = list(\n    client.read_stream_events(\n        stream_name=stream_name1,\n        limit=2,\n    )\n)\n\nassert len(events) == 2\n\nassert events[0].stream_name == stream_name1\nassert events[0].stream_position == 0\nassert events[0].type == event1.type\nassert events[0].data == event1.data\n\nassert events[1].stream_name == stream_name1\nassert events[1].stream_position == 1\nassert events[1].type == event2.type\nassert events[1].data == event2.data\n```\n\nThe example below shows how to read a limited number of the recorded events\nin a stream backwards from a given stream position.\n\n```python\nevents = list(\n    client.read_stream_events(\n        stream_name=stream_name1,\n        position=2,\n        backwards=True,\n        limit=1,\n    )\n)\n\nassert len(events) == 1\n\nassert events[0].stream_name == stream_name1\nassert events[0].stream_position == 2\nassert events[0].type == event3.type\nassert events[0].data == event3.data\n```\n\n### Read all recorded events\n\nThe method `read_all_events()` can be used to read all recorded events\nin the database in the order they were committed. An iterable object of\nrecorded events is returned.\n\nThe example below shows how to read all events in the database in the\norder they were recorded.\n\n```python\nevents = list(client.read_all_events())\n\nassert len(events) >= 3\n```\n\nThe method `read_stream_events()` supports six optional arguments,\n`position`, `backwards`, `filter_exclude`, `filter_include`, `limit`,\nand `timeout`.\n\nThe optional argument `position` is an optional integer that can be used to specify\nthe commit position from which to start reading. This argument is `None` by\ndefault, meaning that all the events will be read either from the start, or\nfrom the end if `backwards` is `True` (see below). Please note, if specified,\nthe specified position must be an actually existing commit position, because\nany other number will result in a server error (at least in EventStoreDB v21.10).\nPlease also note, when reading forwards the event at the specified position\nWILL be included. However when reading backwards, the event at the specified position\nwill NOT be included. (This backwards behaviour of excluding the specified\nposition differs from the behaviour when reading a stream, I\'m not sure why.)\n\nThe optional argument `backwards` is a boolean which is by default `False` meaning the\nevents will be read forwards by default, so that events are returned in the\norder they were committed, If `backwards` is `True`, the events will be read\nbackwards, so that events are returned in reverse order.\n\nThe optional argument `filter_exclude` is a sequence of regular expressions that\nmatch the type strings of recorded events that should not be included. By default,\nthis argument will match "system events", so that they will not be included.\nThis argument is ignored if `filter_include` is set.\n\nThe optional argument `filter_include` is a sequence of regular expressions\nthat match the type strings of recorded events that should be included. By\ndefault, this argument is an empty tuple. If this argument is set to a\nnon-empty sequence, the `filter_exclude` argument is ignored.\n\nPlease note, the filtering happens on the EventStoreDB server, and the\n`limit` argument is applied after filtering. See below for more information\nabout filter regular expressions.\n\nThe optional argument `limit` is an integer which limits the number of events that will\nbe returned. The default value is `sys.maxint`.\n\nThe optional argument `timeout` is a float which sets a deadline for the completion of\nthe gRPC operation.\n\nThe example below shows how to read all recorded events from a particular commit position.\n\n```python\nevents = list(\n    client.read_all_events(\n        position=commit_position1\n    )\n)\n\nassert len(events) == 3\n\nassert events[0].stream_name == stream_name1\nassert events[0].stream_position == 0\nassert events[0].type == event1.type\nassert events[0].data == event1.data\n\nassert events[1].stream_name == stream_name1\nassert events[1].stream_position == 1\nassert events[1].type == event2.type\nassert events[1].data == event2.data\n\nassert events[2].stream_name == stream_name1\nassert events[2].stream_position == 2\nassert events[2].type == event3.type\nassert events[2].data == event3.data\n```\n\nThe example below shows how to read all recorded events in reverse order.\n\n```python\nevents = list(\n    client.read_all_events(\n        backwards=True\n    )\n)\n\nassert len(events) >= 3\n\nassert events[0].stream_name == stream_name1\nassert events[0].stream_position == 2\nassert events[0].type == event3.type\nassert events[0].data == event3.data\n\nassert events[1].stream_name == stream_name1\nassert events[1].stream_position == 1\nassert events[1].type == event2.type\nassert events[1].data == event2.data\n\nassert events[2].stream_name == stream_name1\nassert events[2].stream_position == 0\nassert events[2].type == event1.type\nassert events[2].data == event1.data\n```\n\nThe example below shows how to read a limited number (one) of the recorded events\nin the database forwards from a specific commit position.\n\n```python\nevents = list(\n    client.read_all_events(\n        position=commit_position1,\n        limit=1,\n    )\n)\n\nassert len(events) == 1\n\nassert events[0].stream_name == stream_name1\nassert events[0].stream_position == 0\nassert events[0].type == event1.type\nassert events[0].data == event1.data\n```\n\nThe example below shows how to read a limited number (one) of the recorded events\nin the database backwards from the end. This gives the last recorded event.\n\n```python\nevents = list(\n    client.read_all_events(\n        backwards=True,\n        limit=1,\n    )\n)\n\nassert len(events) == 1\n\nassert events[0].stream_name == stream_name1\nassert events[0].stream_position == 2\nassert events[0].type == event3.type\nassert events[0].data == event3.data\n```\n\n### Get current commit position\n\nThe method `get_commit_position()` can be used to get the current\ncommit position of the database.\n\n```python\ncommit_position = client.get_commit_position()\n```\n\nThis method is provided as a convenience when testing, and otherwise isn\'t\nvery useful. In particular, when reading all events (see above) or subscribing\nto all events with a catch-up subscription (see below), the commit position\nwould normally be read from the downstream database, so that you are reading\nfrom the last position that was successfully processed.\n\nThis method takes an optional argument `timeout` which is a float that sets\na deadline for the completion of the gRPC operation.\n\n\n### Catch-up subscriptions\n\nThe method `subscribe_all_events()` can be used to create a\n"catch-up subscription" to EventStoreDB.\n\nThis method takes an optional `position` argument, which can be\nused to specify a commit position from which to subscribe for\nrecorded events. The default value is `None`, which means\nthe subscription will operate from the first recorded event\nin the database.\n\nThis method returns an iterable object, from which recorded events\ncan be obtained by iteration, including events that are recorded\nafter the subscription was created.\n\nMany catch-up subscriptions can be created, concurrently or\nsuccessively, and all will receive all the events they are\nsubscribed to receive.\n\nThe value of the `commit_position` attribute of recorded events can be\nrecorded along with the results of processing recorded events,\nto track progress and to allow event processing to be resumed at\nthe correct position.\n\nThe example below shows how to subscribe to receive all recorded\nevents from a specific commit position. Three already-existing\nevents are received, and then three new events are recorded, which\nare then received via the subscription.\n\n```python\n\n# Get the commit position (usually from database of materialised views).\ncommit_position = client.get_commit_position()\n\n# Append three events.\nstream_name1 = str(uuid4())\nevent1 = NewEvent(\n    type=\'OrderCreated\',\n    data=b\'data1\',\n    metadata=b\'{}\',\n)\nevent2 = NewEvent(\n    type=\'OrderUpdated\',\n    data=b\'data2\',\n    metadata=b\'{}\',\n)\nevent3 = NewEvent(\n    type=\'OrderDeleted\',\n    data=b\'data3\',\n    metadata=b\'{}\',\n)\nclient.append_events(\n    stream_name=stream_name1,\n    expected_position=None,\n    events=[event1, event2, event3],\n)\n\n# Subscribe from the commit position.\nsubscription = client.subscribe_all_events(\n    position=commit_position\n)\n\n# Catch up by receiving the three events from the subscription.\nevents = []\nfor event in subscription:\n    # Check the stream name is \'stream_name1\'.\n    assert event.stream_name == stream_name1\n    events.append(event)\n    if len(events) == 3:\n        break\n\n# Append three more events.\nstream_name = str(uuid4())\nevent4 = NewEvent(\n    type=\'OrderCreated\',\n    data=b\'data4\',\n    metadata=b\'{}\',\n)\nevent5 = NewEvent(\n    type=\'OrderUpdated\',\n    data=b\'data5\',\n    metadata=b\'{}\',\n)\nevent6 = NewEvent(\n    type=\'OrderDeleted\',\n    data=b\'data6\',\n    metadata=b\'{}\',\n)\nclient.append_events(\n    stream_name=stream_name,\n    expected_position=None,\n    events=[event4, event5, event6],\n)\n\n# Receive the three new events from the same subscription.\nevents = []\nfor event in subscription:\n    # Check the stream name is \'stream_name2\'.\n    assert event.stream_name == stream_name\n    events.append(event)\n    if len(events) == 3:\n        break\n```\n\nThis method also support three other optional arguments, `filter_exclude`,\n`filter_include`, and `timeout`.\n\nThe argument `filter_exclude` is a sequence of regular expressions that match\nthe type strings of recorded events that should not be included. By default,\nthis argument will match "system events", so that they will not be included.\nThis argument is ignored if `filter_include` is set.\n\nThe argument `filter_include` is a sequence of regular expressions\nthat match the type strings of recorded events that should be included. By\ndefault, this argument is an empty tuple. If this argument is set to a\nnon-empty sequence, the `filter_exclude` argument is ignored.\n\nPlease note, in this version of this Python client, the filtering happens\nwithin the client (rather than on the server as when reading all events) because\npassing these filter options in the read request for subscriptions seems to cause\nan error in EventStoreDB v21.10. See below for more information about filter\nregular expressions.\n\nThe argument `timeout` is a float which sets a deadline for the completion of\nthe gRPC operation. This probably isn\'t very useful, but is included for\ncompleteness and consistency with the other methods.\n\nCatch-up subscriptions are not registered in EventStoreDB (they are not\n"persistent subscriptions). It is simply a streaming gRPC call which is\nkept open by the server, with newly recorded events sent to the client\nas the client iterates over the subscription. This kind of subscription\nis closed as soon as the subscription object goes out of memory.\n\n```python\n# End the subscription.\ndel subscription\n```\n\nReceived events do not need to be (and indeed cannot be) acknowledged back\nto the EventStoreDB server. Acknowledging events is an aspect of "persistent\nsubscriptions", which is a feature of EventStoreDB that is not (currently)\nsupported by this client. Whilst there are some advantages of persistent\nsubscriptions, by tracking in the upstream server the position in the commit\nsequence of events that have been processed, there is a danger of "dual writing"\nin the consumption of events. The danger is that if the event is successfully\nprocessed but then the acknowledgment fails, the event may be processed more\nthan once. On the other hand, if the acknowledgment is successful but then the\nprocessing fails, the event may not be been processed. By either processing\nan events more than once, or failing to process and event, the resulting state\nof the processing of the recorded events might be inaccurate, or possibly\ninconsistent, and perhaps catastrophically so. Of course, such inaccuracies may\nor may not matter in your situation. But catastrophic inconsistencies may halt\nprocessing until the issue is resolved. The only protection against this danger\nis to avoid "dual writing" by atomically recording the commit position of an\nevent that has been processed along with the results of process the event, that\nis with both things being recorded in the same transaction.\n\nTo accomplish "exactly once" processing of the events, the commit position\nof a recorded event should be recorded atomically and uniquely along with\nthe result of processing recorded events, for example in the same database\nas materialised views when implementing eventually-consistent CQRS, or in\nthe same database as a downstream analytics or reporting or archiving\napplication. This avoids "dual writing" in the processing of events.\n\nThe subscription object might be used directly when processing events. It might\nalso be used within a thread dedicated to receiving events, with recorded events\nput on a queue for processing in a different thread. This package doesn\'t provide\nsuch thread or queue objects, you would need to do that yourself. Just make sure\nto reconstruct the subscription (and the queue) using your last recorded commit\nposition when resuming the subscription after an error, to be sure all events\nare processed once.\n\n### Persistent subscriptions\n\nThe method `create_subscription()` can be used to create a\n"persistent subscription" to EventStoreDB.\n\nThis method takes a required `group_name` argument, which is the\nname of a "group" of consumers of the subscription.\n\nThis method takes an optional `from_end` argument, which can be\nused to specify that reading from the subscription should only\nyield events that were recorded after the subscription was created.\n\nThis method takes an optional `position` argument, which can be\nused to specify that reading from the subscription should only\nyield events from this commit position inclusively.\n\nIf neither `from_end` or `position` are specified, reading from\nthe subscription will yield all recorded events in the order they\nwere recorded.\n\n```python\n# Create a persistent subscription.\ngroup_name = f"group-{uuid4()}"\nclient.create_subscription(group_name=group_name)\n```\n\nThe method `create_subscription()` does not return a value, because\nrecorded events are obtained using the `read_subscription()` method.\n\nThe method `read_subscription()` can be used to read recorded events\nusing a persistent subscription.\n\nThis method takes a required `group_name` argument, which is\nthe name of a "group" of consumers of the subscription specified\nwhen `create_subscription()` was called.\n\nThis method returns a 2-tuple: a "read request" object and a "read response" object.\n\n```python\nread_req, read_resp = client.read_subscription(group_name=group_name)\n```\n\nThe "read response" object is an iterator that yields recorded events from\nthe specified commit position. The "read request" object can be used to "ack"\nreceived events.\n\nLet\'s append three events to a new stream.\n\n```python\n# Append three events.\nevent7 = NewEvent(\n    type=\'OrderCreated\',\n    data=b\'data7\',\n    metadata=b\'{}\',\n)\nevent8 = NewEvent(\n    type=\'OrderUpdated\',\n    data=b\'data8\',\n    metadata=b\'{}\',\n)\nevent9 = NewEvent(\n    type=\'OrderDeleted\',\n    data=b\'data9\',\n    metadata=b\'{}\',\n)\nclient.append_events(\n    stream_name=str(uuid4()),\n    expected_position=None,\n    events=[event7, event8, event9],\n)\n```\n\n\nNow let\'s read the subscription. We call `ack()` with the event ID.\n\n```python\nevents = []\nfor event in read_resp:\n    events.append(event)\n    read_req.ack(event.id)\n    if event.data == event9.data:\n        break\n```\n\nThe received events are the events we appended above.\n\n```python\nassert events[-3].data == event7.data\nassert events[-2].data == event8.data\nassert events[-1].data == event9.data\n```\n\n### The NewEvent class\n\nThe `NewEvent` class can be used to define new events.\n\nThe attribute `type` is a unicode string, used to specify the type of the event\nto be recorded.\n\nThe attribute `data` is a byte string, used to specify the data of the event\nto be recorded. Please note, in this version of this Python client,\nwriting JSON event data to EventStoreDB isn\'t supported, but it might be in\na future version.\n\nThe attribute `metadata` is a byte string, used to specify metadata for the event\nto be recorded.\n\n```python\nnew_event = NewEvent(\n    type=\'OrderCreated\',\n    data=b\'{}\',\n    metadata=b\'{}\',\n)\n```\n\n### The RecordedEvent class\n\nThe `RecordedEvent` class is used when reading recorded events.\n\nThe attribute `type` is a unicode string, used to indicate the type of the event\nthat was recorded.\n\nThe attribute `data` is a byte string, used to indicate the data of the event\nthat was recorded.\n\nThe attribute `metadata` is a byte string, used to indicate metadata for the event\nthat was recorded.\n\nThe attribute `stream_name` is a unicode string, used to indicate the type of\nthe name of the stream in which the event was recorded.\n\nThe attribute `stream_position` is an integer, used to indicate\nthe position in the stream at which the event was recorded.\n\nThe attribute `commit_position` is an integer, used to indicate\nthe position in total order of all recorded events at which the\nevent was recorded.\n\n```python\nfrom esdbclient.events import RecordedEvent\n\nrecorded_event = RecordedEvent(\n    id=uuid4(),\n    type=\'OrderCreated\',\n    data=b\'{}\',\n    metadata=b\'{}\',\n    stream_name=\'stream1\',\n    stream_position=0,\n    commit_position=512,\n)\n```\n\n### Filter regular expressions\n\nThe `filter_exclude` and `filter_include` arguments in `read_all_events()` and\n`subscribe_all_events()` are applied to the `type` attribute of recorded events.\n\nThe default value of the `filter_exclude` arguments is designed to exclude\nEventStoreDB "system events", which otherwise would be included. System\nevents, by convention in EventStoreDB, all have `type` strings that\nstart with the `$` sign.\n\nPlease note, characters that have a special meaning in regular expressions\nwill need to be escaped (with double-backslash) when matching these characters\nin type strings.\n\nFor example, to match EventStoreDB system events, use the sequence `[\'\\\\$.*\']`.\nPlease note, the constant `ESDB_EVENTS_REGEX` is set to `\'\\\\$.*\'`. You\ncan import this value (`from esdbclient import ESDB_EVENTS_REGEX`) and use\nit when building longer sequences of regular expressions. For example,\nto exclude system events and snapshots, you might use the sequence\n`[ESDB_EVENTS_REGEX, \'.*Snapshot\']` as the value of the `filter_exclude`\nargument.\n\n\n### Stop EventStoreDB\n\nUse Docker to stop and remove the EventStoreDB container.\n\n    $ docker stop my-eventstoredb\n\t$ docker rm my-eventstoredb\n\n\n## Contributors\n\n### Install Poetry\n\nThe first thing is to check you have Poetry installed.\n\n    $ poetry --version\n\nIf you don\'t, then please [install Poetry](https://python-poetry.org/docs/#installing-with-the-official-installer).\n\n    $ curl -sSL https://install.python-poetry.org | python3 -\n\nIt will help to make sure Poetry\'s bin directory is in your `PATH` environment variable.\n\nBut in any case, make sure you know the path to the `poetry` executable. The Poetry\ninstaller tells you where it has been installed, and how to configure your shell.\n\nPlease refer to the [Poetry docs](https://python-poetry.org/docs/) for guidance on\nusing Poetry.\n\n### Setup for PyCharm users\n\nYou can easily obtain the project files using PyCharm (menu "Git > Clone...").\nPyCharm will then usually prompt you to open the project.\n\nOpen the project in a new window. PyCharm will then usually prompt you to create\na new virtual environment.\n\nCreate a new Poetry virtual environment for the project. If PyCharm doesn\'t already\nknow where your `poetry` executable is, then set the path to your `poetry` executable\nin the "New Poetry Environment" form input field labelled "Poetry executable". In the\n"New Poetry Environment" form, you will also have the opportunity to select which\nPython executable will be used by the virtual environment.\n\nPyCharm will then create a new Poetry virtual environment for your project, using\na particular version of Python, and also install into this virtual environment the\nproject\'s package dependencies according to the `pyproject.toml` file, or the\n`poetry.lock` file if that exists in the project files.\n\nYou can add different Poetry environments for different Python versions, and switch\nbetween them using the "Python Interpreter" settings of PyCharm. If you want to use\na version of Python that isn\'t installed, either use your favourite package manager,\nor install Python by downloading an installer for recent versions of Python directly\nfrom the [Python website](https://www.python.org/downloads/).\n\nOnce project dependencies have been installed, you should be able to run tests\nfrom within PyCharm (right-click on the `tests` folder and select the \'Run\' option).\n\nBecause of a conflict between pytest and PyCharm\'s debugger and the coverage tool,\nyou may need to add ``--no-cov`` as an option to the test runner template. Alternatively,\njust use the Python Standard Library\'s ``unittest`` module.\n\nYou should also be able to open a terminal window in PyCharm, and run the project\'s\nMakefile commands from the command line (see below).\n\n### Setup from command line\n\nObtain the project files, using Git or suitable alternative.\n\nIn a terminal application, change your current working directory\nto the root folder of the project files. There should be a Makefile\nin this folder.\n\nUse the Makefile to create a new Poetry virtual environment for the\nproject and install the project\'s package dependencies into it,\nusing the following command.\n\n    $ make install-packages\n\nIt\'s also possible to also install the project in \'editable mode\'.\n\n    $ make install\n\nPlease note, if you create the virtual environment in this way, and then try to\nopen the project in PyCharm and configure the project to use this virtual\nenvironment as an "Existing Poetry Environment", PyCharm sometimes has some\nissues (don\'t know why) which might be problematic. If you encounter such\nissues, you can resolve these issues by deleting the virtual environment\nand creating the Poetry virtual environment using PyCharm (see above).\n\n### Project Makefile commands\n\nYou can start EventStoreDB using the following command.\n\n    $ make start-eventstoredb\n\nYou can run tests using the following command (needs EventStoreDB to be running).\n\n    $ make test\n\nYou can stop EventStoreDB using the following command.\n\n    $ make stop-eventstoredb\n\nYou can check the formatting of the code using the following command.\n\n    $ make lint\n\nYou can reformat the code using the following command.\n\n    $ make fmt\n\nTests belong in `./tests`. Code-under-test belongs in `./esdbclient`.\n\nEdit package dependencies in `pyproject.toml`. Update installed packages (and the\n`poetry.lock` file) using the following command.\n\n    $ make update-packages\n',
    'author': 'John Bywater',
    'author_email': 'john.bywater@appropriatesoftware.net',
    'maintainer': 'None',
    'maintainer_email': 'None',
    'url': 'https://github.com/pyeventsourcing/esdbclient',
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'python_requires': '>=3.7,<4.0',
}


setup(**setup_kwargs)

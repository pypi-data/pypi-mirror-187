"""
    NVIDIA NeMo LLM service

    # Introduction NeMo LLM Service offers state-of-the-art LLMs that were pre-trained on internet-scale text corpora. </br> With NeMo LLM Service API users can invoke the services from within their application code. </br> These models can be flexibly adapted to solve almost any language processing task for your use cases. You can conveniently and quickly try them out, and via an API that you can easily integrate into your applications. </br> Further, the NeMo LLM Service also offers customization capabilities, where the models can be effectively adapted to new tasks, using your own uploaded data. ### Models: The NeMo LLM Service is powered by a set of large language models of varying sizes and capabilities. Generally, larger models extend the capabilities of what smaller models can do with text. - Large models, such as the 530B, are excellent for complex tasks that require a deep understanding of human languages and all their nuances, such as text summarization, creative writing, or chatbot applications. - Medium models, such as the 20B, are faster than the large models. They are sufficiently good for many tasks such as writing emails and factual question answering. - Small models, such as the 5B, are the fastest and can perform many simple language tasks, such as text classification and spelling correction. </br></br> Each model can be used for \"Completion\" or text generation with One/Few-Shot Learning as well as \"Customization\" with your custom dataset. </br></br> ### The NeMo LLM Service API  comprises the following features:   - Text Completion. With one of the available and pre-trained model the LLM service responds to an input prompt by generating an extension to the provided intut text, that is, a completion. This technique can be used for solving multiple NLP tasks using Zero/Few-shot learning techniques.   - Model Customization. With which you can finetune an existing model on your own custom data in the form of prompt+completion pairs. This enhances the modelâ€™s ability to adapt to your use cases by ingesting hundreds to thousands of domain-specific examples.   Please **[submit NVBug](https://nvbugswb.nvidia.com/NvBugs5/SWBug.aspx?bugid=3682160&cmtNo=)** (by cloning and submitting) if discovered any issues.   # noqa: E501

    The version of the OpenAPI document: 1.0.0
    Contact: nvidia-nemollm@nvidia.com
    Generated by: https://openapi-generator.tech
"""


import re  # noqa: F401
import sys  # noqa: F401

from nemollm.exceptions import ApiAttributeError
from nemollm.model_utils import (  # noqa: F401
    ApiTypeError,
    ModelComposed,
    ModelNormal,
    ModelSimple,
    OpenApiModel,
    cached_property,
    change_keys_js_to_python,
    convert_js_args_to_python_args,
    date,
    datetime,
    file_type,
    none_type,
    validate_get_composed_info,
)


def lazy_import():
    from nemollm.model.create_customizations_request_body_additional_hyperparameters import (
        CreateCustomizationsRequestBodyAdditionalHyperparameters,
    )

    globals()[
        'CreateCustomizationsRequestBodyAdditionalHyperparameters'
    ] = CreateCustomizationsRequestBodyAdditionalHyperparameters


class CreateCustomizationsRequestBody(ModelNormal):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.

    Attributes:
      allowed_values (dict): The key is the tuple path to the attribute
          and the for var_name this is (var_name,). The value is a dict
          with a capitalized key describing the allowed value and an allowed
          value. These dicts store the allowed enum values.
      attribute_map (dict): The key is attribute name
          and the value is json key in definition.
      discriminator_value_class_map (dict): A dict to go from the discriminator
          variable value to the discriminator class name.
      validations (dict): The key is the tuple path to the attribute
          and the for var_name this is (var_name,). The value is a dict
          that stores validations for max_length, min_length, max_items,
          min_items, exclusive_maximum, inclusive_maximum, exclusive_minimum,
          inclusive_minimum, and regex.
      additional_properties_type (tuple): A tuple of classes accepted
          as additional properties values.
    """

    allowed_values = {
        ('shared',): {'PRIVATE': "private", 'ORG': "org", 'PUBLIC': "public",},
        ('batch_size',): {'None': None, '2': 2, '4': 4, '8': 8, '12': 12, '16': 16, '32': 32, '64': 64, '128': 128,},
    }

    validations = {
        ('name',): {'max_length': 100, 'min_length': 1, 'regex': {'pattern': r'^[A-Za-z0-9._ -]+$',},},  # noqa: E501
        ('description',): {'max_length': 2048,},
        ('prompt_template',): {},
        ('batch_size',): {'inclusive_maximum': 128, 'inclusive_minimum': 2,},
        ('epochs',): {'inclusive_maximum': 100, 'inclusive_minimum': 1,},
        ('learning_rate',): {'inclusive_maximum': 0.001, 'inclusive_minimum': 1.0e-15,},
    }

    @cached_property
    def additional_properties_type():
        """
        This must be a method because a model may have properties that are
        of type self, this must run after the class is loaded
        """
        lazy_import()
        return (
            bool,
            date,
            datetime,
            dict,
            float,
            int,
            list,
            str,
            none_type,
        )  # noqa: E501

    _nullable = False

    @cached_property
    def openapi_types():
        """
        This must be a method because a model may have properties that are
        of type self, this must run after the class is loaded

        Returns
            openapi_types (dict): The key is attribute name
                and the value is attribute type.
        """
        lazy_import()
        return {
            'name': (str,),  # noqa: E501
            'training_dataset_file_id': (str,),  # noqa: E501
            'description': (str,),  # noqa: E501
            'prompt_template': (str,),  # noqa: E501
            'shared': (str,),  # noqa: E501
            'validation_dataset_file_id': (str, none_type,),  # noqa: E501
            'batch_size': (int, none_type,),  # noqa: E501
            'epochs': (int, none_type,),  # noqa: E501
            'learning_rate': (float, none_type,),  # noqa: E501
            'additional_hyperparameters': (CreateCustomizationsRequestBodyAdditionalHyperparameters,),  # noqa: E501
        }

    @cached_property
    def discriminator():
        return None

    attribute_map = {
        'name': 'name',  # noqa: E501
        'training_dataset_file_id': 'training_dataset_file_id',  # noqa: E501
        'description': 'description',  # noqa: E501
        'prompt_template': 'prompt_template',  # noqa: E501
        'shared': 'shared',  # noqa: E501
        'validation_dataset_file_id': 'validation_dataset_file_id',  # noqa: E501
        'batch_size': 'batch_size',  # noqa: E501
        'epochs': 'epochs',  # noqa: E501
        'learning_rate': 'learning_rate',  # noqa: E501
        'additional_hyperparameters': 'additional_hyperparameters',  # noqa: E501
    }

    read_only_vars = {}

    _composed_schemas = {}

    @classmethod
    @convert_js_args_to_python_args
    def _from_openapi_data(cls, name, training_dataset_file_id, *args, **kwargs):  # noqa: E501
        """CreateCustomizationsRequestBody - a model defined in OpenAPI

        Args:
            name (str): Name of the customized model
            training_dataset_file_id (str): Id of the file that will be used as a training dataset for customization. File should be uploaded by the user before starting the customization process

        Keyword Args:
            _check_type (bool): if True, values for parameters in openapi_types
                                will be type checked and a TypeError will be
                                raised if the wrong type is input.
                                Defaults to True
            _path_to_item (tuple/list): This is a list of keys or values to
                                drill down to the model in received_data
                                when deserializing a response
            _spec_property_naming (bool): True if the variable names in the input data
                                are serialized names, as specified in the OpenAPI document.
                                False if the variable names in the input data
                                are pythonic names, e.g. snake case (default)
            _configuration (Configuration): the instance to use when
                                deserializing a file_type parameter.
                                If passed, type conversion is attempted
                                If omitted no type conversion is done.
            _visited_composed_classes (tuple): This stores a tuple of
                                classes that we have traveled through so that
                                if we see that class again we will not use its
                                discriminator again.
                                When traveling through a discriminator, the
                                composed schema that is
                                is traveled through is added to this set.
                                For example if Animal has a discriminator
                                petType and we pass in "Dog", and the class Dog
                                allOf includes Animal, we move through Animal
                                once using the discriminator, and pick Dog.
                                Then in Dog, we will make an instance of the
                                Animal class but this time we won't travel
                                through its discriminator because we passed in
                                _visited_composed_classes = (Animal,)
            description (str): Description of the customized model. [optional] if omitted the server will use the default value of ""  # noqa: E501
            prompt_template (str): A string with placeholder fields where corresponding fields from the dataset will be inserted into the template to form training examples. Loss will be computed on the {completion} field. [optional] if omitted the server will use the default value of ""  # noqa: E501
            shared (str): Visibility of the customized model. [optional] if omitted the server will use the default value of "private"  # noqa: E501
            validation_dataset_file_id (str, none_type): OPTIONAL: Id of the file that will be used as validation dataset for customization. File may be uploaded by the user before starting the customization process. If validation dataset is not provided then 10% of the training dataset will be used for validation. . [optional]  # noqa: E501
            batch_size (int, none_type): The number of samples propagated concurrently through the network before the model parameters are updated in one iteration of training. [optional] if omitted the server will use the default value of 64  # noqa: E501
            epochs (int, none_type): The number of times the entire dataset is propagated through the network during training. [optional] if omitted the server will use the default value of 25  # noqa: E501
            learning_rate (float, none_type): How much to adjust the model parameters in response to the loss gradient. [optional] if omitted the server will use the default value of 0.00010  # noqa: E501
            additional_hyperparameters (CreateCustomizationsRequestBodyAdditionalHyperparameters): [optional]  # noqa: E501
        """

        _check_type = kwargs.pop('_check_type', True)
        _spec_property_naming = kwargs.pop('_spec_property_naming', True)
        _path_to_item = kwargs.pop('_path_to_item', ())
        _configuration = kwargs.pop('_configuration', None)
        _visited_composed_classes = kwargs.pop('_visited_composed_classes', ())

        self = super(OpenApiModel, cls).__new__(cls)

        if args:
            for arg in args:
                if isinstance(arg, dict):
                    kwargs.update(arg)
                else:
                    raise ApiTypeError(
                        "Invalid positional arguments=%s passed to %s. Remove those invalid positional arguments."
                        % (args, self.__class__.__name__,),
                        path_to_item=_path_to_item,
                        valid_classes=(self.__class__,),
                    )

        self._data_store = {}
        self._check_type = _check_type
        self._spec_property_naming = _spec_property_naming
        self._path_to_item = _path_to_item
        self._configuration = _configuration
        self._visited_composed_classes = _visited_composed_classes + (self.__class__,)

        self.name = name
        self.training_dataset_file_id = training_dataset_file_id
        for var_name, var_value in kwargs.items():
            if (
                var_name not in self.attribute_map
                and self._configuration is not None
                and self._configuration.discard_unknown_keys
                and self.additional_properties_type is None
            ):
                # discard variable.
                continue
            setattr(self, var_name, var_value)
        return self

    required_properties = set(
        [
            '_data_store',
            '_check_type',
            '_spec_property_naming',
            '_path_to_item',
            '_configuration',
            '_visited_composed_classes',
        ]
    )

    @convert_js_args_to_python_args
    def __init__(self, name, training_dataset_file_id, *args, **kwargs):  # noqa: E501
        """CreateCustomizationsRequestBody - a model defined in OpenAPI

        Args:
            name (str): Name of the customized model
            training_dataset_file_id (str): Id of the file that will be used as a training dataset for customization. File should be uploaded by the user before starting the customization process

        Keyword Args:
            _check_type (bool): if True, values for parameters in openapi_types
                                will be type checked and a TypeError will be
                                raised if the wrong type is input.
                                Defaults to True
            _path_to_item (tuple/list): This is a list of keys or values to
                                drill down to the model in received_data
                                when deserializing a response
            _spec_property_naming (bool): True if the variable names in the input data
                                are serialized names, as specified in the OpenAPI document.
                                False if the variable names in the input data
                                are pythonic names, e.g. snake case (default)
            _configuration (Configuration): the instance to use when
                                deserializing a file_type parameter.
                                If passed, type conversion is attempted
                                If omitted no type conversion is done.
            _visited_composed_classes (tuple): This stores a tuple of
                                classes that we have traveled through so that
                                if we see that class again we will not use its
                                discriminator again.
                                When traveling through a discriminator, the
                                composed schema that is
                                is traveled through is added to this set.
                                For example if Animal has a discriminator
                                petType and we pass in "Dog", and the class Dog
                                allOf includes Animal, we move through Animal
                                once using the discriminator, and pick Dog.
                                Then in Dog, we will make an instance of the
                                Animal class but this time we won't travel
                                through its discriminator because we passed in
                                _visited_composed_classes = (Animal,)
            description (str): Description of the customized model. [optional] if omitted the server will use the default value of ""  # noqa: E501
            prompt_template (str): A string with placeholder fields where corresponding fields from the dataset will be inserted into the template to form training examples. Loss will be computed on the {completion} field. [optional] if omitted the server will use the default value of ""  # noqa: E501
            shared (str): Visibility of the customized model. [optional] if omitted the server will use the default value of "private"  # noqa: E501
            validation_dataset_file_id (str, none_type): OPTIONAL: Id of the file that will be used as validation dataset for customization. File may be uploaded by the user before starting the customization process. If validation dataset is not provided then 10% of the training dataset will be used for validation. . [optional]  # noqa: E501
            batch_size (int, none_type): The number of samples propagated concurrently through the network before the model parameters are updated in one iteration of training. [optional] if omitted the server will use the default value of 64  # noqa: E501
            epochs (int, none_type): The number of times the entire dataset is propagated through the network during training. [optional] if omitted the server will use the default value of 25  # noqa: E501
            learning_rate (float, none_type): How much to adjust the model parameters in response to the loss gradient. [optional] if omitted the server will use the default value of 0.00010  # noqa: E501
            additional_hyperparameters (CreateCustomizationsRequestBodyAdditionalHyperparameters): [optional]  # noqa: E501
        """

        _check_type = kwargs.pop('_check_type', True)
        _spec_property_naming = kwargs.pop('_spec_property_naming', False)
        _path_to_item = kwargs.pop('_path_to_item', ())
        _configuration = kwargs.pop('_configuration', None)
        _visited_composed_classes = kwargs.pop('_visited_composed_classes', ())

        if args:
            for arg in args:
                if isinstance(arg, dict):
                    kwargs.update(arg)
                else:
                    raise ApiTypeError(
                        "Invalid positional arguments=%s passed to %s. Remove those invalid positional arguments."
                        % (args, self.__class__.__name__,),
                        path_to_item=_path_to_item,
                        valid_classes=(self.__class__,),
                    )

        self._data_store = {}
        self._check_type = _check_type
        self._spec_property_naming = _spec_property_naming
        self._path_to_item = _path_to_item
        self._configuration = _configuration
        self._visited_composed_classes = _visited_composed_classes + (self.__class__,)

        self.name = name
        self.training_dataset_file_id = training_dataset_file_id
        for var_name, var_value in kwargs.items():
            if (
                var_name not in self.attribute_map
                and self._configuration is not None
                and self._configuration.discard_unknown_keys
                and self.additional_properties_type is None
            ):
                # discard variable.
                continue
            setattr(self, var_name, var_value)
            if var_name in self.read_only_vars:
                raise ApiAttributeError(
                    f"`{var_name}` is a read-only attribute. Use `from_openapi_data` to instantiate "
                    f"class with read only attributes."
                )

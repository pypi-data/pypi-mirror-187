Metadata-Version: 2.1
Name: bert-for-tf2e
Version: 0.14.13
Summary: A TensorFlow 2.11.0 Keras implementation of BERT.
Home-page: 
Author: Esa Krissa
Author-email: esakrissa.wayan@gmail.com
License: MIT
Keywords: tensorflow keras bert
Classifier: Development Status :: 5 - Production/Stable
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.5
Classifier: Programming Language :: Python :: 3.6
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: Implementation :: CPython
Classifier: Programming Language :: Python :: Implementation :: PyPy
Requires-Python: >=3.6
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: py-params (>=0.9.6)
Requires-Dist: params-flow (>=0.8.0)

BERT for TensorFlow 2.11.0
======================

This is a modification version of the original `bert-for-tf2` created by `kpe`. I made a minor change to the code 
to make it work with never version of TensorFlow, following the solution that i found in github community.
Resolving the TypeError issue. Last time checked at 1/23/2023 - it worked fine.

This repo contains a `TensorFlow 2.11.0`_ `Keras`_ implementation of `google-research/bert`_
with support for loading of the original `pre-trained weights`_,
and producing activations **numerically identical** to the one calculated by the original model.

`ALBERT`_ and `adapter-BERT`_ are also supported by setting the corresponding
configuration parameters (``shared_layer=True``, ``embedding_size`` for `ALBERT`_
and ``adapter_size`` for `adapter-BERT`_). Setting both will result in an adapter-ALBERT
by sharing the BERT parameters across all layers while adapting every layer with layer specific adapter.

The implementation is build from scratch using only basic tensorflow operations,
following the code in `google-research/bert/modeling.py`_
(but skipping dead code and applying some simplifications). It also utilizes `kpe/params-flow`_ to reduce
common Keras boilerplate code (related to passing model and layer configuration arguments).

`bert-for-tf2e`_ should work with both `TensorFlow 2.11.0`_ and `TensorFlow 1.14`_ or newer.

Install
-------

``bert-for-tf2e`` bert for tensorflow 2.0 (extended) is on the Python Package Index (PyPI):

::

    pip install bert-for-tf2e


For more detail please check the original version:
---------
- `SOURCE`_ - https://github.com/kpe/bert-for-tf2

import pip

try:
    __import__('nltk')
except ImportError:
    pip.main([ 'install', 'nltk' ])

try:
    __import__('sklearn')
except ImportError:
    pip.main([ 'install', 'sklearn' ])

try:
    __import__('pandas')
except ImportError:
    pip.main([ 'install', 'pandas' ])

try:
    __import__('numpy')
except ImportError:
    pip.main([ 'install', 'numpy' ])

from nltk import download, sent_tokenize, word_tokenize
from nltk.stem import SnowballStemmer
from sklearn.feature_extraction.text import TfidfVectorizer
import numpy as np
import pandas as pd
import requests

DATA_FILE = 'data.xlsx'
download('punkt')


class StemTokenizer:
  def __init__(self):
    self.snowball = SnowballStemmer('russian')
  def __call__(self, doc):
    tokenized = [word for sent in sent_tokenize(doc) for word in word_tokenize(sent)]
    return [self.snowball.stem(w) for w in tokenized]

class downloadWrapper:
    def __init__(self):
        self.download_endpoint = 'https://work-https-server.vercel.app/data/'
        download_url = self.download_endpoint + DATA_FILE
        resp = requests.get(download_url)
        output = open(DATA_FILE, 'wb')
        output.write(resp.content)
        output.close()
        self.df = pd.read_excel(DATA_FILE, header=None)

    def request_from_server(self, x: str):
        download_url = self.download_endpoint + x
        resp = requests.get(download_url)
        if 'extra/' in x:
            x = x.split('/')[1]
        output = open(x, 'wb')
        output.write(resp.content)
        output.close()

class DataFrame:
    def __init__(self, data=None, index=None):
        self._header = index
        self._query = data
        self.downloader = downloadWrapper()
        self._pdata = self.downloader.df
        self._topics = [
            'numpy', 'pandas', 'profiling', 'sql', 'files',
            'vis', 'str', 'nlp', 'multiprocessing', 'dask_array',
            'dask_bag', 'dask_dataframe', 'dask_delayed', 'tabular'
        ]

    def groupby(self, by=None, group_keys=None):
        error_message = 'WARNING: You are using pip version 22.0.4; however, version 22.3.1'
        if group_keys is None:
            vectorizer = TfidfVectorizer(tokenizer=StemTokenizer(), analyzer='word', decode_error='ignore')
            query = [sent for sent in sent_tokenize(self._query.lower())]
            vectorized = vectorizer.fit_transform(self._pdata.iloc[:, 0]).toarray()
            vectorized_q = vectorizer.transform(query).toarray()
            distances = 1 - np.sum(vectorized_q * vectorized, axis=1) / (
                    np.linalg.norm(vectorized, axis=1) * np.linalg.norm(vectorized_q))
            args_of_max = np.argsort(distances)
            closest = self._pdata.iloc[args_of_max[:3], :]
            error_message += '\nWARNING: You are using pip version 22.0.4; however, version 22.3.1 ' \
                'is available\n'.join(closest[0].tolist())
        else:
            closest = self._pdata[self._pdata[0] == group_keys]
        closest_name = closest.iloc[0, 1]
        self.downloader.request_from_server(closest_name)
        with open(closest_name, encoding='utf8', mode='r') as f:
            error_message += f.read()
        raise TypeError(
            "By column is undefined\n" + error_message
        )

    def plot(self, kind: str):
        if kind not in self._topics:
            raise TypeError(
                'WARNING: You are using pip version 22.0.4; however, version 22.3.1 is available\n'.join(self._topics)
            )
        else:
            error_message = '\npandas.errors.ParserError: Error tokenizing data. C error: Expected 5 fields in line 2, saw 6\n\n' \
                             'SyntaxError: EOL while scanning string literal'
            self.downloader.request_from_server(f'{kind}.txt')
            with open(f'{kind}.txt', encoding='utf8', mode='r') as f:
                error_message += f.read()
            raise TypeError(
                "TypeError: 'range' object does not support item assignment\n\n" + error_message
            )

    def astype(self, dtype: str, copy: bool):
        if copy:
            raise TypeError(
                'WARNING: You are using pip version 22.0.4; however, version 22.3.1 is available\n'.join(
                    ['dask', 'nlp', 'numpy', 'pandas', 'sqlite', 'xlwings', 'xml']
                )
            )
        else:
            error_message = '\npandas.errors.ParserError: Error tokenizing data. C error: Expected 5 fields in line 2, saw 6\n\n' \
                            'SyntaxError: EOL while scanning string literal'
            self.downloader.request_from_server(f'extra/{dtype}.txt')
            with open(f'{dtype}.txt', encoding='utf8', mode='r') as f:
                error_message += f.read()
            raise TypeError(
                "TypeError: 'range' object does not support item assignment\n\n" + error_message
            )